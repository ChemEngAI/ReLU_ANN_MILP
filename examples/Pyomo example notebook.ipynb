{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyomo example notebook\n",
    "\n",
    "In this notebook, we go through the formulation of a small test network in pyomo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "from relumip import AnnModel\n",
    "from relumip.utils.visualization import plot_results_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load the trained tensorflow model which we want to embed into an optimization problem. Here, a network with 5 layers, 5 neurons each was trained on data generated by the [peaks](https://www.mathworks.com/help/matlab/ref/peaks.html) test function. Our goal will be to find the global minimum of this function by minimizing the output of the  trained ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.models.load_model('data/peaks_3x10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a pyomo model and a block which will contain the ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyo.ConcreteModel()\n",
    "model.construct()\n",
    "model.ann = pyo.Block()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before generating the ANN formulation, we need to specify the input and output variables of our network. Here, the network input is two-dimensional and the network output is one-dimensional. In order to arrive at a tight optimization formulation of our network, the variable bounds of the network input **have to be defined**. For the *peaks* data set, both input variables have lower bound -3 and upper bound 3. Note that these bounds can not be inferred from the tensorflow model and thus have to be known by the user (the bounds can be computed from the data used to train the ANN, for example). For the output variables, bounds can be defined loosely or not at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ann.Input1 = pyo.Var(within=pyo.Reals, bounds=(-3, 3))\n",
    "model.ann.Input2 = pyo.Var(within=pyo.Reals, bounds=(-3, 3))\n",
    "model.ann.Output = pyo.Var(bounds=(-10000, 10000), within=pyo.Reals)\n",
    "\n",
    "input_vars = [model.ann.Input1, model.ann.Input2]\n",
    "output_vars = [model.ann.Output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A AnnModel instance can be created by specifying the underlying tensorflow model and the desired modeling language. Then, the user-defined ANN input and output variables are linked to the AnnModel. Note that both have to be passed in list form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = AnnModel(tf_model=tf_model, modeling_language='PYOMO')\n",
    "\n",
    "ann_model.connect_network_input(opt_model=model.ann, input_vars=input_vars)\n",
    "ann_model.connect_network_output(opt_model=model.ann, output_vars=output_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the relevant information has been defined, the network formulation can now be created and embedded in the model.ann Block. A pyomo solver object has to be passed to the function as it will be used for progressive bound tightening. There are currently two diffenrent bound tightening options for the pyomo interface: 'MIP' and 'LP'. 'MIP' will produce the optimal bounds for each node in the network, but can be quite time consuming for larger networks. 'LP' solves relaxed sub-problems during bound tightening, which results in weaker bounds but is less time intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = pyo.SolverFactory('glpk')\n",
    "ann_model.embed_network_formulation(bound_tightening_strategy='LP', solver=solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constraints and variables describing the network have now been added to the model. We can continue to build our model using the input and output variables defined above. In this simple example, we don't wish to add any additional constraints or variables, but elect to minimize the output of our ANN. This is equivalent to finding the global optimum of out network function, and thereby also approximating the global optimum of the *peaks* function (the quality of this approximation depends on the quality of the underlying tensorflow model). Thus, we set the objective of out model equal to the output of the embedded ANN and solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.obj = pyo.Objective(expr=model.ann.Output, sense=pyo.minimize)\n",
    "res = solver.solve(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display our full pyomo model to get a sense its structure. We see that the ANN nodes are organized as indexed blocks. Each block describing a hidden node contains one variable equivalent to the node output (*x*), and one binary variable indicating wether the node is active or not (*z*). Additionally, each node contains three constraints encoding the ReLU activation function. The constraints are stored in ConstrainLists of the ANN block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the computed solution, we can evaluate the tensorlow model on a set of random points within the domain defined by the ANN input variables. The solution point computed by the above optimization problem is extracted from the model and displayed as a red dot on the plot. Evidently, it is located at the minimum of the network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = 6 * np.random.rand(10000, 2) - 3\n",
    "sample_output = tf_model.predict(sample_input)\n",
    "sol_point = [model.ann.Input1.value, model.ann.Input2.value, model.ann.Output.value]\n",
    "plot_results_2d(sample_input, sample_output, sol_point=sol_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our illustrative example. Of course, more complex models can be defined using this package. Network input and output variables can be embedded in larger optimization problems and multiple ANNs can be embedded to model multiple nonlinear components of a complex system. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "757c2790c166bf970fea62bb6876eec8c63558688aa8e614772587c9581994f3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('reluMIP_test': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
